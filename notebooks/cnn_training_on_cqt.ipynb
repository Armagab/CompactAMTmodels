{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da11ed48-2d6c-437f-89a0-240da89dc852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSED_ROOT: E:\\DL_audiotomidi\\preprocessed_dataset\n",
      "PROJECT_ROOT: E:\\DL_audiotomidi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "PREPROCESSED_ROOT = PROJECT_ROOT / \"preprocessed_dataset\"\n",
    "\n",
    "print(\"PREPROCESSED_ROOT:\", PREPROCESSED_ROOT)\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ec1c8b-9e9a-444e-82c0-244c3232140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from models.cnn_amt import CNNTemporal\n",
    "from scripts.dataset_helpers import create_dataloaders\n",
    "from scripts.evaluate import evaluate, frame_level_f1\n",
    "\n",
    "import wandb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b447d810-8f97-41c2-af9a-b7fe8840112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPEC_TYPE=\"mel\" for Mel-Spectrogram\n",
    "SPEC_TYPE = \"cqt\"\n",
    "# N_FREQ_BINS=229 for Mel-Spectrogram\n",
    "N_FREQ_BINS = 252\n",
    "N_PITCHES = 88\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "CHUNK_LEN = 1024\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "BASE_LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "# WARMUP for Learning Rate\n",
    "WARMUP_RATIO = 0.05\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "HOP_LENGTH = 512\n",
    "SR = 22050\n",
    "# Binarization threshold\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367d0e6a-311e-4ed4-9b7f-c016a3250c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd68a02c-504f-4881-9969-99b11d8e3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 61\n",
      "Val batches: 9\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = create_dataloaders(\n",
    "    root_dir=str(PREPROCESSED_ROOT),\n",
    "    spec_type=SPEC_TYPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(\"train batches:\", len(train_loader))\n",
    "print(\"val batches:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f9ddac-9009-4249-9030-c4716fd964c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6100\n",
      "305\n"
     ]
    }
   ],
   "source": [
    "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
    "print(\"training steps:\", num_training_steps)\n",
    "num_warmup_steps = int(WARMUP_RATIO * num_training_steps)\n",
    "print(\"warmup steps:\",num_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0da07ca-df71-4098-ad00-ffc69bcdc5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(current_step: int):\n",
    "    # warmup\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / max(1, num_warmup_steps)\n",
    "\n",
    "    # cosine decay\n",
    "    progress = float(current_step - num_warmup_steps) / max(\n",
    "        1, num_training_steps - num_warmup_steps\n",
    "    )\n",
    "    return 0.5 * (1.0 + math.cos(math.pi * progress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05301a46-1642-4960-9546-1df19202cc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTemporal(\n",
       "  (stem): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (cnn2d): Sequential(\n",
       "    (0): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 1), bias=False)\n",
       "    )\n",
       "    (1): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 1), bias=False)\n",
       "    )\n",
       "    (2): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 1), bias=False)\n",
       "    )\n",
       "    (3): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (bn_final_2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (temporal): Sequential(\n",
       "    (0): PreActResBlock1D(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    )\n",
       "    (1): PreActResBlock1D(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "    )\n",
       "    (2): PreActResBlock1D(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (head): Conv1d(128, 88, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNTemporal(\n",
    "    n_freq_bins=N_FREQ_BINS,\n",
    "    n_pitches=N_PITCHES\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=BASE_LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5731b94-9efa-4b54-8ee3-8b9caace835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 800,952\n"
     ]
    }
   ],
   "source": [
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"trainable parameters: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58df652-c3ac-494c-a495-05446d8b848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function weighted with a positive weight value\n",
    "pos_weight_value = 5.0\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.full((N_PITCHES,), pos_weight_value, device=DEVICE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1cef5e0-45f2-4884-a5bd-26dc2564806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    log_interval: int = 50\n",
    "):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch_idx, (spec, target) in enumerate(dataloader):\n",
    "\n",
    "        spec = spec.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        logits = model(spec)\n",
    "\n",
    "        # BCEWithLogitsLoss by all (frame, pitch)\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.shape[-1]),\n",
    "            target.reshape(-1, target.shape[-1])\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        batch_f1 = frame_level_f1(logits.detach(), target.detach(), threshold=THRESHOLD)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_f1 += batch_f1\n",
    "        num_batches += 1\n",
    "\n",
    "    epoch_loss = running_loss / max(1, num_batches)\n",
    "    epoch_f1 = running_f1 / max(1, num_batches)\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c77a02-549d-401e-97e0-b63169ae1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          scheduler,\n",
    "          device,\n",
    "          n_epochs,\n",
    "          run=None,\n",
    "          checkpoint_path=None,\n",
    "          threshold=0.5,\n",
    "          hop_length=512,\n",
    "          sr=22050,\n",
    "          log_interval=50,\n",
    "):\n",
    "    \n",
    "    global_step = 0\n",
    "    best_val_frame_f1 = 0.0\n",
    "\n",
    "    total_start = time.time()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # training phase\n",
    "        train_loss, train_frame_f1 = train_one_epoch(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "            log_interval=log_interval\n",
    "        )\n",
    "        \n",
    "        train_time_sec = time.time() - epoch_start\n",
    "\n",
    "        global_step = epoch * len(train_dataloader)\n",
    "\n",
    "        # validation phase\n",
    "        val_start = time.time()\n",
    "        val_loss, val_frame_f1, _ = evaluate(\n",
    "            model=model,\n",
    "            dataloader=val_dataloader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            threshold=threshold,\n",
    "            hop_length=hop_length,\n",
    "            sr=sr,\n",
    "            onset_tolerance=0.05,\n",
    "            compute_note_f1=False\n",
    "        )\n",
    "\n",
    "        val_time = time.time() - val_start\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch}/{n_epochs}] \"\n",
    "            f\"train_loss={train_loss:.4f}, train_F1={train_frame_f1:.4f} | \"\n",
    "            f\"val_loss={val_loss:.4f}, val_F1={val_frame_f1:.4f} | \"\n",
    "            f\"train_time={train_time_sec:.1f}s\"\n",
    "        )\n",
    "\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        #wandb logging\n",
    "        if run is not None:\n",
    "            run.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train/loss\": train_loss,\n",
    "                    \"train/frame_F1\": train_frame_f1,\n",
    "                    \"val/loss\": val_loss,\n",
    "                    \"val/frame_F1\": val_frame_f1,\n",
    "                    \"lr\": current_lr,\n",
    "                    \"time/train_epoch_sec\": epoch_time,\n",
    "                },\n",
    "                step=global_step\n",
    "            )\n",
    "\n",
    "        #saving the best checkpoint by val_frame metric\n",
    "        if checkpoint_path is not None and val_frame_f1 > best_val_frame_f1:\n",
    "            best_val_frame_f1 = val_frame_f1\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model.state_dict()\n",
    "                },\n",
    "                checkpoint_path\n",
    "            )\n",
    "            print(f\"*** New best frame-F1={best_val_frame_f1:.4f}, saved to {checkpoint_path} ***\")\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"\\n=== TOTAL TRAINING TIME: {total_time/3600:.2f} hours ===\")\n",
    "\n",
    "    if run is not None:\n",
    "        run.log({\"time/total_hours\": total_time / 3600.0}, step=global_step)\n",
    "\n",
    "    return best_val_frame_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50edbf9b-c455-438d-8d83-fb67c870d7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DL_audiotomidi\\checkpoints\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
    "print(CHECKPOINT_DIR)\n",
    "\n",
    "best_ckpt_path = CHECKPOINT_DIR / f\"cnn_{SPEC_TYPE}_best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0907663-736a-496f-bd63-87373d0c3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_config = {\n",
    "    \"model\": \"CNNTemporal\",\n",
    "    \"spec_type\": SPEC_TYPE,\n",
    "    \"n_freq_bins\": N_FREQ_BINS,\n",
    "    \"n_pitches\": N_PITCHES,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"chunk_len\": CHUNK_LEN,\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"base_lr\": BASE_LR,\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"warmup_ratio\": WARMUP_RATIO,\n",
    "    \"seed\": SEED,\n",
    "    \"hop_length\": HOP_LENGTH,\n",
    "    \"sr\": SR,\n",
    "    \"threshold\": THRESHOLD,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bf6b5ea-2a9f-4b3c-94c8-73e14c882933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\DL_audiotomidi\\notebooks\\wandb\\run-20251115_175032-8eictikf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/8eictikf' target=\"_blank\">CNNTemporal_cqt</a></strong> to <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/8eictikf' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/8eictikf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/100 ===\n",
      "[Epoch 1/100] train_loss=0.5024, train_F1=0.2666 | val_loss=0.6207, val_F1=0.1917 | train_time=42.5s\n",
      "*** New best frame-F1=0.1917, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 2/100 ===\n",
      "[Epoch 2/100] train_loss=0.4594, train_F1=0.3228 | val_loss=0.5623, val_F1=0.1684 | train_time=40.3s\n",
      "\n",
      "=== Epoch 3/100 ===\n",
      "[Epoch 3/100] train_loss=0.4371, train_F1=0.3371 | val_loss=0.6219, val_F1=0.1566 | train_time=39.2s\n",
      "\n",
      "=== Epoch 4/100 ===\n",
      "[Epoch 4/100] train_loss=0.4241, train_F1=0.3516 | val_loss=0.7692, val_F1=0.1416 | train_time=39.7s\n",
      "\n",
      "=== Epoch 5/100 ===\n",
      "[Epoch 5/100] train_loss=0.4099, train_F1=0.3676 | val_loss=0.4253, val_F1=0.2610 | train_time=45.1s\n",
      "*** New best frame-F1=0.2610, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 6/100 ===\n",
      "[Epoch 6/100] train_loss=0.3999, train_F1=0.3970 | val_loss=0.3616, val_F1=0.3490 | train_time=43.2s\n",
      "*** New best frame-F1=0.3490, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 7/100 ===\n",
      "[Epoch 7/100] train_loss=0.3741, train_F1=0.4195 | val_loss=0.4040, val_F1=0.3438 | train_time=39.0s\n",
      "\n",
      "=== Epoch 8/100 ===\n",
      "[Epoch 8/100] train_loss=0.3636, train_F1=0.4437 | val_loss=0.3709, val_F1=0.3563 | train_time=39.4s\n",
      "*** New best frame-F1=0.3563, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 9/100 ===\n",
      "[Epoch 9/100] train_loss=0.3438, train_F1=0.4632 | val_loss=0.3060, val_F1=0.4508 | train_time=39.3s\n",
      "*** New best frame-F1=0.4508, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 10/100 ===\n",
      "[Epoch 10/100] train_loss=0.3391, train_F1=0.4788 | val_loss=0.4779, val_F1=0.2502 | train_time=39.7s\n",
      "\n",
      "=== Epoch 11/100 ===\n",
      "[Epoch 11/100] train_loss=0.3421, train_F1=0.4802 | val_loss=0.4586, val_F1=0.2985 | train_time=39.3s\n",
      "\n",
      "=== Epoch 12/100 ===\n",
      "[Epoch 12/100] train_loss=0.3231, train_F1=0.4988 | val_loss=0.2952, val_F1=0.4142 | train_time=43.7s\n",
      "\n",
      "=== Epoch 13/100 ===\n",
      "[Epoch 13/100] train_loss=0.2963, train_F1=0.5233 | val_loss=0.3689, val_F1=0.3359 | train_time=42.4s\n",
      "\n",
      "=== Epoch 14/100 ===\n",
      "[Epoch 14/100] train_loss=0.3072, train_F1=0.5276 | val_loss=0.2897, val_F1=0.4192 | train_time=45.3s\n",
      "\n",
      "=== Epoch 15/100 ===\n",
      "[Epoch 15/100] train_loss=0.3113, train_F1=0.5153 | val_loss=0.4201, val_F1=0.2879 | train_time=40.7s\n",
      "\n",
      "=== Epoch 16/100 ===\n",
      "[Epoch 16/100] train_loss=0.2812, train_F1=0.5408 | val_loss=0.2249, val_F1=0.5675 | train_time=40.3s\n",
      "*** New best frame-F1=0.5675, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 17/100 ===\n",
      "[Epoch 17/100] train_loss=0.2787, train_F1=0.5625 | val_loss=0.2470, val_F1=0.5289 | train_time=42.6s\n",
      "\n",
      "=== Epoch 18/100 ===\n",
      "[Epoch 18/100] train_loss=0.2804, train_F1=0.5548 | val_loss=0.2571, val_F1=0.4752 | train_time=40.3s\n",
      "\n",
      "=== Epoch 19/100 ===\n",
      "[Epoch 19/100] train_loss=0.2668, train_F1=0.5747 | val_loss=0.2989, val_F1=0.3975 | train_time=41.1s\n",
      "\n",
      "=== Epoch 20/100 ===\n",
      "[Epoch 20/100] train_loss=0.2737, train_F1=0.5599 | val_loss=0.3005, val_F1=0.4597 | train_time=45.5s\n",
      "\n",
      "=== Epoch 21/100 ===\n",
      "[Epoch 21/100] train_loss=0.2581, train_F1=0.5713 | val_loss=0.2542, val_F1=0.5315 | train_time=47.1s\n",
      "\n",
      "=== Epoch 22/100 ===\n",
      "[Epoch 22/100] train_loss=0.2556, train_F1=0.5798 | val_loss=0.1997, val_F1=0.5753 | train_time=52.4s\n",
      "*** New best frame-F1=0.5753, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 23/100 ===\n",
      "[Epoch 23/100] train_loss=0.2519, train_F1=0.5950 | val_loss=0.2462, val_F1=0.5599 | train_time=54.3s\n",
      "\n",
      "=== Epoch 24/100 ===\n",
      "[Epoch 24/100] train_loss=0.2548, train_F1=0.5943 | val_loss=0.1910, val_F1=0.5936 | train_time=53.0s\n",
      "*** New best frame-F1=0.5936, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 25/100 ===\n",
      "[Epoch 25/100] train_loss=0.2521, train_F1=0.5929 | val_loss=0.2380, val_F1=0.4860 | train_time=54.5s\n",
      "\n",
      "=== Epoch 26/100 ===\n",
      "[Epoch 26/100] train_loss=0.2355, train_F1=0.6085 | val_loss=0.2141, val_F1=0.5995 | train_time=54.5s\n",
      "*** New best frame-F1=0.5995, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 27/100 ===\n",
      "[Epoch 27/100] train_loss=0.2292, train_F1=0.6198 | val_loss=0.1960, val_F1=0.5693 | train_time=53.4s\n",
      "\n",
      "=== Epoch 28/100 ===\n",
      "[Epoch 28/100] train_loss=0.2387, train_F1=0.6135 | val_loss=0.2042, val_F1=0.6060 | train_time=44.6s\n",
      "*** New best frame-F1=0.6060, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 29/100 ===\n",
      "[Epoch 29/100] train_loss=0.2324, train_F1=0.6126 | val_loss=0.2990, val_F1=0.4005 | train_time=41.1s\n",
      "\n",
      "=== Epoch 30/100 ===\n",
      "[Epoch 30/100] train_loss=0.2359, train_F1=0.6199 | val_loss=0.2403, val_F1=0.5341 | train_time=40.0s\n",
      "\n",
      "=== Epoch 31/100 ===\n",
      "[Epoch 31/100] train_loss=0.2174, train_F1=0.6217 | val_loss=0.1929, val_F1=0.6078 | train_time=39.7s\n",
      "*** New best frame-F1=0.6078, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 32/100 ===\n",
      "[Epoch 32/100] train_loss=0.2396, train_F1=0.6176 | val_loss=0.2033, val_F1=0.5570 | train_time=44.2s\n",
      "\n",
      "=== Epoch 33/100 ===\n",
      "[Epoch 33/100] train_loss=0.2235, train_F1=0.6302 | val_loss=0.2024, val_F1=0.6503 | train_time=40.9s\n",
      "*** New best frame-F1=0.6503, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 34/100 ===\n",
      "[Epoch 34/100] train_loss=0.2191, train_F1=0.6370 | val_loss=0.2201, val_F1=0.5018 | train_time=40.8s\n",
      "\n",
      "=== Epoch 35/100 ===\n",
      "[Epoch 35/100] train_loss=0.2279, train_F1=0.6318 | val_loss=0.1970, val_F1=0.5785 | train_time=42.8s\n",
      "\n",
      "=== Epoch 36/100 ===\n",
      "[Epoch 36/100] train_loss=0.2251, train_F1=0.6362 | val_loss=0.2077, val_F1=0.5597 | train_time=47.0s\n",
      "\n",
      "=== Epoch 37/100 ===\n",
      "[Epoch 37/100] train_loss=0.2264, train_F1=0.6230 | val_loss=0.1853, val_F1=0.6213 | train_time=46.0s\n",
      "\n",
      "=== Epoch 38/100 ===\n",
      "[Epoch 38/100] train_loss=0.2146, train_F1=0.6464 | val_loss=0.1769, val_F1=0.6341 | train_time=40.4s\n",
      "\n",
      "=== Epoch 39/100 ===\n",
      "[Epoch 39/100] train_loss=0.2087, train_F1=0.6481 | val_loss=0.2133, val_F1=0.6428 | train_time=39.9s\n",
      "\n",
      "=== Epoch 40/100 ===\n",
      "[Epoch 40/100] train_loss=0.2174, train_F1=0.6362 | val_loss=0.1714, val_F1=0.6455 | train_time=40.9s\n",
      "\n",
      "=== Epoch 41/100 ===\n",
      "[Epoch 41/100] train_loss=0.2173, train_F1=0.6465 | val_loss=0.2228, val_F1=0.5021 | train_time=43.5s\n",
      "\n",
      "=== Epoch 42/100 ===\n",
      "[Epoch 42/100] train_loss=0.2061, train_F1=0.6511 | val_loss=0.1676, val_F1=0.6170 | train_time=45.8s\n",
      "\n",
      "=== Epoch 43/100 ===\n",
      "[Epoch 43/100] train_loss=0.2045, train_F1=0.6566 | val_loss=0.2070, val_F1=0.6980 | train_time=48.5s\n",
      "*** New best frame-F1=0.6980, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 44/100 ===\n",
      "[Epoch 44/100] train_loss=0.2020, train_F1=0.6616 | val_loss=0.1704, val_F1=0.6908 | train_time=43.5s\n",
      "\n",
      "=== Epoch 45/100 ===\n",
      "[Epoch 45/100] train_loss=0.2044, train_F1=0.6617 | val_loss=0.1749, val_F1=0.6042 | train_time=51.6s\n",
      "\n",
      "=== Epoch 46/100 ===\n",
      "[Epoch 46/100] train_loss=0.2055, train_F1=0.6570 | val_loss=0.1536, val_F1=0.6716 | train_time=54.9s\n",
      "\n",
      "=== Epoch 47/100 ===\n",
      "[Epoch 47/100] train_loss=0.2032, train_F1=0.6611 | val_loss=0.7630, val_F1=0.3437 | train_time=54.3s\n",
      "\n",
      "=== Epoch 48/100 ===\n",
      "[Epoch 48/100] train_loss=0.2026, train_F1=0.6667 | val_loss=0.1539, val_F1=0.6757 | train_time=55.7s\n",
      "\n",
      "=== Epoch 49/100 ===\n",
      "[Epoch 49/100] train_loss=0.1950, train_F1=0.6652 | val_loss=0.2082, val_F1=0.6721 | train_time=47.1s\n",
      "\n",
      "=== Epoch 50/100 ===\n",
      "[Epoch 50/100] train_loss=0.1996, train_F1=0.6691 | val_loss=0.1570, val_F1=0.6630 | train_time=48.2s\n",
      "\n",
      "=== Epoch 51/100 ===\n",
      "[Epoch 51/100] train_loss=0.1957, train_F1=0.6687 | val_loss=0.1727, val_F1=0.6041 | train_time=46.9s\n",
      "\n",
      "=== Epoch 52/100 ===\n",
      "[Epoch 52/100] train_loss=0.1872, train_F1=0.6799 | val_loss=0.1558, val_F1=0.6411 | train_time=52.2s\n",
      "\n",
      "=== Epoch 53/100 ===\n",
      "[Epoch 53/100] train_loss=0.1914, train_F1=0.6695 | val_loss=0.1510, val_F1=0.6837 | train_time=52.9s\n",
      "\n",
      "=== Epoch 54/100 ===\n",
      "[Epoch 54/100] train_loss=0.1869, train_F1=0.6778 | val_loss=0.1437, val_F1=0.6836 | train_time=40.8s\n",
      "\n",
      "=== Epoch 55/100 ===\n",
      "[Epoch 55/100] train_loss=0.1925, train_F1=0.6760 | val_loss=0.1539, val_F1=0.6531 | train_time=43.6s\n",
      "\n",
      "=== Epoch 56/100 ===\n",
      "[Epoch 56/100] train_loss=0.1873, train_F1=0.6845 | val_loss=0.1482, val_F1=0.6886 | train_time=47.4s\n",
      "\n",
      "=== Epoch 57/100 ===\n",
      "[Epoch 57/100] train_loss=0.1935, train_F1=0.6810 | val_loss=0.2843, val_F1=0.6334 | train_time=42.4s\n",
      "\n",
      "=== Epoch 58/100 ===\n",
      "[Epoch 58/100] train_loss=0.2015, train_F1=0.6661 | val_loss=0.1492, val_F1=0.7027 | train_time=45.3s\n",
      "*** New best frame-F1=0.7027, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 59/100 ===\n",
      "[Epoch 59/100] train_loss=0.1943, train_F1=0.6795 | val_loss=0.1437, val_F1=0.7143 | train_time=41.7s\n",
      "*** New best frame-F1=0.7143, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 60/100 ===\n",
      "[Epoch 60/100] train_loss=0.1873, train_F1=0.6781 | val_loss=0.1408, val_F1=0.6962 | train_time=44.8s\n",
      "\n",
      "=== Epoch 61/100 ===\n",
      "[Epoch 61/100] train_loss=0.1842, train_F1=0.6878 | val_loss=0.1440, val_F1=0.6948 | train_time=51.1s\n",
      "\n",
      "=== Epoch 62/100 ===\n",
      "[Epoch 62/100] train_loss=0.1804, train_F1=0.6835 | val_loss=0.1606, val_F1=0.6959 | train_time=47.1s\n",
      "\n",
      "=== Epoch 63/100 ===\n",
      "[Epoch 63/100] train_loss=0.1829, train_F1=0.6912 | val_loss=0.1407, val_F1=0.6803 | train_time=45.4s\n",
      "\n",
      "=== Epoch 64/100 ===\n",
      "[Epoch 64/100] train_loss=0.1836, train_F1=0.6896 | val_loss=0.1453, val_F1=0.6539 | train_time=45.1s\n",
      "\n",
      "=== Epoch 65/100 ===\n",
      "[Epoch 65/100] train_loss=0.1761, train_F1=0.6964 | val_loss=0.1419, val_F1=0.6667 | train_time=43.0s\n",
      "\n",
      "=== Epoch 66/100 ===\n",
      "[Epoch 66/100] train_loss=0.1888, train_F1=0.6857 | val_loss=0.1543, val_F1=0.7295 | train_time=45.6s\n",
      "*** New best frame-F1=0.7295, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 67/100 ===\n",
      "[Epoch 67/100] train_loss=0.2006, train_F1=0.6819 | val_loss=0.1554, val_F1=0.6282 | train_time=49.7s\n",
      "\n",
      "=== Epoch 68/100 ===\n",
      "[Epoch 68/100] train_loss=0.1952, train_F1=0.6640 | val_loss=0.1443, val_F1=0.7089 | train_time=46.0s\n",
      "\n",
      "=== Epoch 69/100 ===\n",
      "[Epoch 69/100] train_loss=0.1828, train_F1=0.6989 | val_loss=0.1339, val_F1=0.7036 | train_time=50.3s\n",
      "\n",
      "=== Epoch 70/100 ===\n",
      "[Epoch 70/100] train_loss=0.1826, train_F1=0.6906 | val_loss=0.1337, val_F1=0.7196 | train_time=53.0s\n",
      "\n",
      "=== Epoch 71/100 ===\n",
      "[Epoch 71/100] train_loss=0.1740, train_F1=0.7015 | val_loss=0.1328, val_F1=0.7065 | train_time=55.0s\n",
      "\n",
      "=== Epoch 72/100 ===\n",
      "[Epoch 72/100] train_loss=0.1737, train_F1=0.7012 | val_loss=0.1334, val_F1=0.7027 | train_time=49.3s\n",
      "\n",
      "=== Epoch 73/100 ===\n",
      "[Epoch 73/100] train_loss=0.1773, train_F1=0.7021 | val_loss=0.1388, val_F1=0.6719 | train_time=46.4s\n",
      "\n",
      "=== Epoch 74/100 ===\n",
      "[Epoch 74/100] train_loss=0.1745, train_F1=0.6987 | val_loss=0.1334, val_F1=0.6829 | train_time=43.7s\n",
      "\n",
      "=== Epoch 75/100 ===\n",
      "[Epoch 75/100] train_loss=0.1707, train_F1=0.7070 | val_loss=0.1390, val_F1=0.6586 | train_time=55.7s\n",
      "\n",
      "=== Epoch 76/100 ===\n",
      "[Epoch 76/100] train_loss=0.1807, train_F1=0.6981 | val_loss=0.1404, val_F1=0.6598 | train_time=45.3s\n",
      "\n",
      "=== Epoch 77/100 ===\n",
      "[Epoch 77/100] train_loss=0.1683, train_F1=0.7044 | val_loss=0.1294, val_F1=0.7332 | train_time=50.2s\n",
      "*** New best frame-F1=0.7332, saved to E:\\DL_audiotomidi\\checkpoints\\cnn_cqt_best.pt ***\n",
      "\n",
      "=== Epoch 78/100 ===\n",
      "[Epoch 78/100] train_loss=0.1703, train_F1=0.7036 | val_loss=0.1307, val_F1=0.6941 | train_time=47.3s\n",
      "\n",
      "=== Epoch 79/100 ===\n",
      "[Epoch 79/100] train_loss=0.1735, train_F1=0.7069 | val_loss=0.1271, val_F1=0.7127 | train_time=49.4s\n",
      "\n",
      "=== Epoch 80/100 ===\n",
      "[Epoch 80/100] train_loss=0.1666, train_F1=0.7165 | val_loss=0.1285, val_F1=0.7317 | train_time=47.7s\n",
      "\n",
      "=== Epoch 81/100 ===\n",
      "[Epoch 81/100] train_loss=0.1724, train_F1=0.7060 | val_loss=0.1297, val_F1=0.6960 | train_time=48.3s\n",
      "\n",
      "=== Epoch 82/100 ===\n",
      "[Epoch 82/100] train_loss=0.1696, train_F1=0.7084 | val_loss=0.1267, val_F1=0.7117 | train_time=41.0s\n",
      "\n",
      "=== Epoch 83/100 ===\n",
      "[Epoch 83/100] train_loss=0.1664, train_F1=0.7149 | val_loss=0.1268, val_F1=0.7246 | train_time=45.4s\n",
      "\n",
      "=== Epoch 84/100 ===\n",
      "[Epoch 84/100] train_loss=0.1724, train_F1=0.7041 | val_loss=0.1271, val_F1=0.7116 | train_time=54.3s\n",
      "\n",
      "=== Epoch 85/100 ===\n",
      "[Epoch 85/100] train_loss=0.1655, train_F1=0.7073 | val_loss=0.1257, val_F1=0.7106 | train_time=42.3s\n",
      "\n",
      "=== Epoch 86/100 ===\n",
      "[Epoch 86/100] train_loss=0.1660, train_F1=0.7118 | val_loss=0.1252, val_F1=0.7135 | train_time=46.3s\n",
      "\n",
      "=== Epoch 87/100 ===\n",
      "[Epoch 87/100] train_loss=0.1677, train_F1=0.7098 | val_loss=0.1261, val_F1=0.7100 | train_time=49.3s\n",
      "\n",
      "=== Epoch 88/100 ===\n",
      "[Epoch 88/100] train_loss=0.1673, train_F1=0.7124 | val_loss=0.1257, val_F1=0.7128 | train_time=46.6s\n",
      "\n",
      "=== Epoch 89/100 ===\n",
      "[Epoch 89/100] train_loss=0.1704, train_F1=0.7113 | val_loss=0.1254, val_F1=0.7271 | train_time=50.9s\n",
      "\n",
      "=== Epoch 90/100 ===\n",
      "[Epoch 90/100] train_loss=0.1638, train_F1=0.7142 | val_loss=0.1255, val_F1=0.7134 | train_time=45.2s\n",
      "\n",
      "=== Epoch 91/100 ===\n",
      "[Epoch 91/100] train_loss=0.1642, train_F1=0.7123 | val_loss=0.1248, val_F1=0.7268 | train_time=53.5s\n",
      "\n",
      "=== Epoch 92/100 ===\n",
      "[Epoch 92/100] train_loss=0.1680, train_F1=0.7064 | val_loss=0.1266, val_F1=0.7044 | train_time=48.0s\n",
      "\n",
      "=== Epoch 93/100 ===\n",
      "[Epoch 93/100] train_loss=0.1610, train_F1=0.7153 | val_loss=0.1257, val_F1=0.7141 | train_time=48.7s\n",
      "\n",
      "=== Epoch 94/100 ===\n",
      "[Epoch 94/100] train_loss=0.1738, train_F1=0.7144 | val_loss=0.1241, val_F1=0.7276 | train_time=48.7s\n",
      "\n",
      "=== Epoch 95/100 ===\n",
      "[Epoch 95/100] train_loss=0.1607, train_F1=0.7174 | val_loss=0.1254, val_F1=0.7116 | train_time=50.5s\n",
      "\n",
      "=== Epoch 96/100 ===\n",
      "[Epoch 96/100] train_loss=0.1651, train_F1=0.7136 | val_loss=0.1254, val_F1=0.7127 | train_time=44.0s\n",
      "\n",
      "=== Epoch 97/100 ===\n",
      "[Epoch 97/100] train_loss=0.1717, train_F1=0.7134 | val_loss=0.1242, val_F1=0.7223 | train_time=43.2s\n",
      "\n",
      "=== Epoch 98/100 ===\n",
      "[Epoch 98/100] train_loss=0.1609, train_F1=0.7099 | val_loss=0.1262, val_F1=0.7082 | train_time=52.0s\n",
      "\n",
      "=== Epoch 99/100 ===\n",
      "[Epoch 99/100] train_loss=0.1650, train_F1=0.7109 | val_loss=0.1258, val_F1=0.7139 | train_time=47.3s\n",
      "\n",
      "=== Epoch 100/100 ===\n",
      "[Epoch 100/100] train_loss=0.1736, train_F1=0.7144 | val_loss=0.1247, val_F1=0.7231 | train_time=53.4s\n",
      "\n",
      "=== TOTAL TRAINING TIME: 1.52 hours ===\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>lr</td><td>▅█████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>time/total_hours</td><td>▁</td></tr><tr><td>time/train_epoch_sec</td><td>▁▁▃▁▁▄█▇▁▃▁▂▄▇█▇▃▂▂▄▄▄▆▆▅▄▆▅▅▂█▄▆▄▆▅▅▆▃▅</td></tr><tr><td>train/frame_F1</td><td>▁▂▃▄▄▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>train/loss</td><td>█▆▆▅▅▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/frame_F1</td><td>▁▁▃▂▃▃▄▃▆▆▆▄▆▇▇▇▇▇▆▇▇██▇████▇▇██████████</td></tr><tr><td>val/loss</td><td>▆█▄▃▄▃▂▂▂▂▂▂▁▂▁▁▂▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>time/total_hours</td><td>1.51773</td></tr><tr><td>time/train_epoch_sec</td><td>53.39701</td></tr><tr><td>train/frame_F1</td><td>0.71437</td></tr><tr><td>train/loss</td><td>0.17365</td></tr><tr><td>val/frame_F1</td><td>0.72313</td></tr><tr><td>val/loss</td><td>0.12469</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CNNTemporal_cqt</strong> at: <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/8eictikf' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/8eictikf</a><br> View project at: <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251115_175032-8eictikf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation frame-F1: 0.7331993100581946\n"
     ]
    }
   ],
   "source": [
    "with wandb.init(\n",
    "    project=\"DL_audiotomidi\",\n",
    "    name=\"CNNTemporal_cqt\",\n",
    "    config=wandb_config\n",
    ") as run:\n",
    "\n",
    "    best_val_frame_f1 = train(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=DEVICE,\n",
    "        n_epochs=NUM_EPOCHS,\n",
    "        run=run,\n",
    "        checkpoint_path=best_ckpt_path,\n",
    "        threshold=THRESHOLD,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        sr=SR,\n",
    "        log_interval=50\n",
    "    )\n",
    "\n",
    "print(\"Best validation frame-F1:\", best_val_frame_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180ab358-5a3f-46f7-8ea6-8ec774d4274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNTemporal(\n",
       "  (stem): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (cnn2d): Sequential(\n",
       "    (0): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 1), bias=False)\n",
       "    )\n",
       "    (1): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 1), bias=False)\n",
       "    )\n",
       "    (2): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 1), bias=False)\n",
       "    )\n",
       "    (3): PreActResBlock2D(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (skip): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (bn_final_2d): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (temporal): Sequential(\n",
       "    (0): PreActResBlock1D(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    )\n",
       "    (1): PreActResBlock1D(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
       "    )\n",
       "    (2): PreActResBlock1D(\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (head): Conv1d(128, 88, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(best_ckpt_path, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "146d88d9-76b9-402b-a131-080652e81bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataset_helpers import PianoRollDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TEST_CHUNK_LEN = None # for CNN we don't need to chop the spectrogram into chunks, \n",
    "                      # but for RNN and CRNN we have to\n",
    "TEST_BATCH_SIZE = 1\n",
    "\n",
    "test_ds = PianoRollDataset(\n",
    "    root_dir=str(PREPROCESSED_ROOT),\n",
    "    split=\"test\",\n",
    "    spec_type=SPEC_TYPE,\n",
    "    chunk_len=TEST_CHUNK_LEN,\n",
    "    random_crop=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a63d15d-2b93-4f83-b6ef-ce11e39883ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test frame-level metrics ===\n",
      "accuracy: 96.99%\n",
      "precision: 68.80%\n",
      "recall: 79.87%\n",
      "frame_f1: 73.92%\n"
     ]
    }
   ],
   "source": [
    "from scripts.evaluate import compute_frame_micro_metrics\n",
    "\n",
    "frame_metrics = compute_frame_micro_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    DEVICE,\n",
    "    threshold=0.6\n",
    ")\n",
    "\n",
    "print(\"=== Test frame-level metrics ===\")\n",
    "for k, v in frame_metrics.items():\n",
    "    if k in (\"tp\", \"fp\", \"fn\"):\n",
    "        continue\n",
    "    print(f\"{k}: {v * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e4be3c5-314b-4155-bee8-121ce24220ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test note-level metrics ===\n",
      "accuracy: 36.44%\n",
      "precision: 43.40%\n",
      "recall: 69.46%\n",
      "note_f1: 53.42%\n"
     ]
    }
   ],
   "source": [
    "from scripts.evaluate import compute_note_micro_metrics\n",
    "\n",
    "note_metrics = compute_note_micro_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    DEVICE,\n",
    "    threshold=0.7,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    sr=SR,\n",
    "    onset_tolerance=0.05\n",
    ")\n",
    "\n",
    "print(\"=== Test note-level metrics ===\")\n",
    "for k, v in note_metrics.items():\n",
    "    if k in (\"tp\", \"fp\", \"fn\"):\n",
    "        continue\n",
    "    print(f\"{k}: {v * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c64e38d-8c7e-4c03-a9ce-6a62fd266808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.inference.py import get_piano_roll, predict, plot_comparison, measure_efficiency\n",
    "\n",
    "# Test track with corresponding MIDI\n",
    "AUDIO_PATH = \"test_long.wav\"\n",
    "MIDI_PATH = \"test_long.midi\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio, _ = librosa.load(AUDIO_PATH, sr=SR, mono=True)\n",
    "\n",
    "pred_probs, spec = predict(model, audio, DEVICE)\n",
    "\n",
    "gt_roll = get_piano_roll(MIDI_PATH, SR, HOP_LENGTH)\n",
    "\n",
    "plot_comparison(spec, pred_probs, gt_roll, SR, HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1fc69-f943-43e3-859b-1082c4f85d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = measure_efficiency(model, device='cpu', duration_sec=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMT (PyTorch CUDA)",
   "language": "python",
   "name": "amt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
