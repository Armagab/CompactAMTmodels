{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da11ed48-2d6c-437f-89a0-240da89dc852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSED_ROOT: E:\\DL_audiotomidi\\preprocessed_dataset\n",
      "PROJECT_ROOT: E:\\DL_audiotomidi\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "PREPROCESSED_ROOT = PROJECT_ROOT / \"preprocessed_dataset\"\n",
    "\n",
    "print(\"PREPROCESSED_ROOT:\", PREPROCESSED_ROOT)\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ec1c8b-9e9a-444e-82c0-244c3232140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from models.rnn_amt import CompactBiGRU\n",
    "from scripts.dataset_helpers import create_dataloaders\n",
    "from scripts.evaluate import evaluate, frame_level_f1\n",
    "\n",
    "import wandb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b447d810-8f97-41c2-af9a-b7fe8840112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPEC_TYPE=\"mel\" for Mel-Spectrogram\n",
    "SPEC_TYPE = \"cqt\"\n",
    "# N_FREQ_BINS=229 for Mel-Spectrogram\n",
    "N_FREQ_BINS = 252\n",
    "N_PITCHES = 88\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "CHUNK_LEN = 512\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "BASE_LR = 3e-4\n",
    "WEIGHT_DECAY = 5e-5\n",
    "# WARMUP for Learning Rate\n",
    "WARMUP_RATIO = 0.1\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "HOP_LENGTH = 512\n",
    "SR = 22050\n",
    "# Binarization threshold\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367d0e6a-311e-4ed4-9b7f-c016a3250c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd68a02c-504f-4881-9969-99b11d8e3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 61\n",
      "Val batches: 9\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = create_dataloaders(\n",
    "    root_dir=str(PREPROCESSED_ROOT),\n",
    "    spec_type=SPEC_TYPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(\"train batches:\", len(train_loader))\n",
    "print(\"val batches:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f9ddac-9009-4249-9030-c4716fd964c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6100\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
    "print(\"training steps:\", num_training_steps)\n",
    "num_warmup_steps = int(WARMUP_RATIO * num_training_steps)\n",
    "print(\"warmup steps:\",num_warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0da07ca-df71-4098-ad00-ffc69bcdc5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(current_step: int):\n",
    "    # warmup\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / max(1, num_warmup_steps)\n",
    "\n",
    "    # cosine decay\n",
    "    progress = float(current_step - num_warmup_steps) / max(\n",
    "        1, num_training_steps - num_warmup_steps\n",
    "    )\n",
    "    return 0.5 * (1.0 + math.cos(math.pi * progress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05301a46-1642-4960-9546-1df19202cc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompactBiGRU(\n",
       "  (input_proj): Linear(in_features=252, out_features=96, bias=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): ResidualBiGRUBlock(\n",
       "      (gru): GRU(96, 160, batch_first=True, bidirectional=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (proj): Linear(in_features=96, out_features=320, bias=True)\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): ResidualBiGRUBlock(\n",
       "      (gru): GRU(320, 160, batch_first=True, bidirectional=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=320, out_features=88, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CompactBiGRU(\n",
    "    input_dim=N_FREQ_BINS,\n",
    "    n_pitches=N_PITCHES,\n",
    "    proj_dim=96,\n",
    "    hidden_dim=160,\n",
    "    num_blocks=2,\n",
    "    dropout=0.2,\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=BASE_LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127d1a8b-7d3a-440c-b0f7-a3f32e4b1953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 795,256\n"
     ]
    }
   ],
   "source": [
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a58df652-c3ac-494c-a495-05446d8b848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function weighted with a positive weight value\n",
    "pos_weight_value = 5.0\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(\n",
    "    pos_weight=torch.full((N_PITCHES,), pos_weight_value, device=DEVICE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1cef5e0-45f2-4884-a5bd-26dc2564806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "    log_interval: int = 50\n",
    "):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for batch_idx, (spec, target) in enumerate(dataloader):\n",
    "\n",
    "        spec = spec.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        logits = model(spec)\n",
    "\n",
    "        # BCEWithLogitsLoss by all (frame, pitch)\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.shape[-1]),\n",
    "            target.reshape(-1, target.shape[-1])\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        batch_f1 = frame_level_f1(logits.detach(), target.detach(), threshold=THRESHOLD)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_f1 += batch_f1\n",
    "        num_batches += 1\n",
    "\n",
    "    epoch_loss = running_loss / max(1, num_batches)\n",
    "    epoch_f1 = running_f1 / max(1, num_batches)\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96c77a02-549d-401e-97e0-b63169ae1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          scheduler,\n",
    "          device,\n",
    "          n_epochs,\n",
    "          run=None,\n",
    "          checkpoint_path=None,\n",
    "          threshold=0.5,\n",
    "          hop_length=512,\n",
    "          sr=22050,\n",
    "          log_interval=50,\n",
    "):\n",
    "    \n",
    "    global_step = 0\n",
    "    best_val_frame_f1 = 0.0\n",
    "\n",
    "    total_start = time.time()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        # training phase\n",
    "        train_loss, train_frame_f1 = train_one_epoch(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "            log_interval=log_interval\n",
    "        )\n",
    "        \n",
    "        train_time_sec = time.time() - epoch_start\n",
    "\n",
    "        global_step = epoch * len(train_dataloader)\n",
    "\n",
    "        # validation phase\n",
    "        val_start = time.time()\n",
    "        val_loss, val_frame_f1, _ = evaluate(\n",
    "            model=model,\n",
    "            dataloader=val_dataloader,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            threshold=threshold,\n",
    "            hop_length=hop_length,\n",
    "            sr=sr,\n",
    "            onset_tolerance=0.05,\n",
    "            compute_note_f1=False\n",
    "        )\n",
    "\n",
    "        val_time = time.time() - val_start\n",
    "        epoch_time = time.time() - epoch_start\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch}/{n_epochs}] \"\n",
    "            f\"train_loss={train_loss:.4f}, train_F1={train_frame_f1:.4f} | \"\n",
    "            f\"val_loss={val_loss:.4f}, val_F1={val_frame_f1:.4f} | \"\n",
    "            f\"train_time={train_time_sec:.1f}s\"\n",
    "        )\n",
    "\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        #wandb logging\n",
    "        if run is not None:\n",
    "            run.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train/loss\": train_loss,\n",
    "                    \"train/frame_F1\": train_frame_f1,\n",
    "                    \"val/loss\": val_loss,\n",
    "                    \"val/frame_F1\": val_frame_f1,\n",
    "                    \"lr\": current_lr,\n",
    "                    \"time/train_epoch_sec\": epoch_time,\n",
    "                },\n",
    "                step=global_step\n",
    "            )\n",
    "\n",
    "        #saving the best checkpoint by val_frame metric\n",
    "        if checkpoint_path is not None and val_frame_f1 > best_val_frame_f1:\n",
    "            best_val_frame_f1 = val_frame_f1\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model.state_dict()\n",
    "                },\n",
    "                checkpoint_path\n",
    "            )\n",
    "            print(f\"*** New best frame-F1={best_val_frame_f1:.4f}, saved to {checkpoint_path} ***\")\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"\\n=== TOTAL TRAINING TIME: {total_time/3600:.2f} hours ===\")\n",
    "\n",
    "    if run is not None:\n",
    "        run.log({\"time/total_hours\": total_time / 3600.0}, step=global_step)\n",
    "\n",
    "    return best_val_frame_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50edbf9b-c455-438d-8d83-fb67c870d7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\DL_audiotomidi\\checkpoints\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
    "print(CHECKPOINT_DIR)\n",
    "\n",
    "best_ckpt_path = CHECKPOINT_DIR / f\"compactgru_{SPEC_TYPE}_best_cqt.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0907663-736a-496f-bd63-87373d0c3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_config = {\n",
    "    \"model\": \"BiGRU\",\n",
    "    \"spec_type\": SPEC_TYPE,\n",
    "    \"n_freq_bins\": N_FREQ_BINS,\n",
    "    \"n_pitches\": N_PITCHES,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"chunk_len\": CHUNK_LEN,\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"base_lr\": BASE_LR,\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"warmup_ratio\": WARMUP_RATIO,\n",
    "    \"seed\": SEED,\n",
    "    \"hop_length\": HOP_LENGTH,\n",
    "    \"sr\": SR,\n",
    "    \"threshold\": THRESHOLD,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bf6b5ea-2a9f-4b3c-94c8-73e14c882933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>E:\\DL_audiotomidi\\notebooks\\wandb\\run-20251117_003624-wvrj8oyq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/wvrj8oyq' target=\"_blank\">CompactBiGRU_cqt</a></strong> to <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/wvrj8oyq' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/wvrj8oyq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/100 ===\n",
      "[Epoch 1/100] train_loss=0.8370, train_F1=0.0956 | val_loss=0.6614, val_F1=0.0768 | train_time=47.4s\n",
      "*** New best frame-F1=0.0768, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 2/100 ===\n",
      "[Epoch 2/100] train_loss=0.6477, train_F1=0.0761 | val_loss=0.4958, val_F1=0.0087 | train_time=51.8s\n",
      "\n",
      "=== Epoch 3/100 ===\n",
      "[Epoch 3/100] train_loss=0.5928, train_F1=0.0490 | val_loss=0.4604, val_F1=0.0362 | train_time=42.6s\n",
      "\n",
      "=== Epoch 4/100 ===\n",
      "[Epoch 4/100] train_loss=0.5496, train_F1=0.1143 | val_loss=0.4218, val_F1=0.2062 | train_time=45.0s\n",
      "*** New best frame-F1=0.2062, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 5/100 ===\n",
      "[Epoch 5/100] train_loss=0.5082, train_F1=0.3151 | val_loss=0.3697, val_F1=0.3864 | train_time=39.3s\n",
      "*** New best frame-F1=0.3864, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 6/100 ===\n",
      "[Epoch 6/100] train_loss=0.4488, train_F1=0.4164 | val_loss=0.3229, val_F1=0.4601 | train_time=47.9s\n",
      "*** New best frame-F1=0.4601, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 7/100 ===\n",
      "[Epoch 7/100] train_loss=0.4083, train_F1=0.4602 | val_loss=0.2903, val_F1=0.4999 | train_time=46.8s\n",
      "*** New best frame-F1=0.4999, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 8/100 ===\n",
      "[Epoch 8/100] train_loss=0.4021, train_F1=0.4792 | val_loss=0.2877, val_F1=0.4757 | train_time=42.6s\n",
      "\n",
      "=== Epoch 9/100 ===\n",
      "[Epoch 9/100] train_loss=0.3688, train_F1=0.4983 | val_loss=0.2595, val_F1=0.5140 | train_time=48.5s\n",
      "*** New best frame-F1=0.5140, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 10/100 ===\n",
      "[Epoch 10/100] train_loss=0.3555, train_F1=0.5059 | val_loss=0.2535, val_F1=0.5140 | train_time=47.7s\n",
      "\n",
      "=== Epoch 11/100 ===\n",
      "[Epoch 11/100] train_loss=0.3427, train_F1=0.5178 | val_loss=0.2548, val_F1=0.5029 | train_time=64.2s\n",
      "\n",
      "=== Epoch 12/100 ===\n",
      "[Epoch 12/100] train_loss=0.3292, train_F1=0.5270 | val_loss=0.2638, val_F1=0.4673 | train_time=64.3s\n",
      "\n",
      "=== Epoch 13/100 ===\n",
      "[Epoch 13/100] train_loss=0.3310, train_F1=0.5328 | val_loss=0.2353, val_F1=0.5285 | train_time=48.7s\n",
      "*** New best frame-F1=0.5285, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 14/100 ===\n",
      "[Epoch 14/100] train_loss=0.3194, train_F1=0.5422 | val_loss=0.2156, val_F1=0.5671 | train_time=44.9s\n",
      "*** New best frame-F1=0.5671, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 15/100 ===\n",
      "[Epoch 15/100] train_loss=0.3064, train_F1=0.5605 | val_loss=0.2138, val_F1=0.5716 | train_time=60.2s\n",
      "*** New best frame-F1=0.5716, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 16/100 ===\n",
      "[Epoch 16/100] train_loss=0.3219, train_F1=0.5434 | val_loss=0.2262, val_F1=0.5218 | train_time=49.9s\n",
      "\n",
      "=== Epoch 17/100 ===\n",
      "[Epoch 17/100] train_loss=0.3038, train_F1=0.5548 | val_loss=0.2076, val_F1=0.5787 | train_time=40.8s\n",
      "*** New best frame-F1=0.5787, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 18/100 ===\n",
      "[Epoch 18/100] train_loss=0.3067, train_F1=0.5691 | val_loss=0.2053, val_F1=0.5712 | train_time=41.6s\n",
      "\n",
      "=== Epoch 19/100 ===\n",
      "[Epoch 19/100] train_loss=0.3024, train_F1=0.5494 | val_loss=0.2017, val_F1=0.5858 | train_time=41.3s\n",
      "*** New best frame-F1=0.5858, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 20/100 ===\n",
      "[Epoch 20/100] train_loss=0.2930, train_F1=0.5645 | val_loss=0.1942, val_F1=0.5791 | train_time=41.9s\n",
      "\n",
      "=== Epoch 21/100 ===\n",
      "[Epoch 21/100] train_loss=0.2861, train_F1=0.5713 | val_loss=0.1897, val_F1=0.5999 | train_time=47.0s\n",
      "*** New best frame-F1=0.5999, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 22/100 ===\n",
      "[Epoch 22/100] train_loss=0.2854, train_F1=0.5675 | val_loss=0.1879, val_F1=0.5993 | train_time=53.9s\n",
      "\n",
      "=== Epoch 23/100 ===\n",
      "[Epoch 23/100] train_loss=0.2816, train_F1=0.5770 | val_loss=0.2052, val_F1=0.5370 | train_time=52.5s\n",
      "\n",
      "=== Epoch 24/100 ===\n",
      "[Epoch 24/100] train_loss=0.2792, train_F1=0.5762 | val_loss=0.1862, val_F1=0.6071 | train_time=44.0s\n",
      "*** New best frame-F1=0.6071, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 25/100 ===\n",
      "[Epoch 25/100] train_loss=0.2874, train_F1=0.5783 | val_loss=0.1942, val_F1=0.5632 | train_time=49.6s\n",
      "\n",
      "=== Epoch 26/100 ===\n",
      "[Epoch 26/100] train_loss=0.2737, train_F1=0.5808 | val_loss=0.1765, val_F1=0.6215 | train_time=44.5s\n",
      "*** New best frame-F1=0.6215, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 27/100 ===\n",
      "[Epoch 27/100] train_loss=0.2645, train_F1=0.5875 | val_loss=0.1881, val_F1=0.5808 | train_time=58.4s\n",
      "\n",
      "=== Epoch 28/100 ===\n",
      "[Epoch 28/100] train_loss=0.2592, train_F1=0.5920 | val_loss=0.1902, val_F1=0.5587 | train_time=48.8s\n",
      "\n",
      "=== Epoch 29/100 ===\n",
      "[Epoch 29/100] train_loss=0.2681, train_F1=0.5836 | val_loss=0.1754, val_F1=0.6144 | train_time=48.8s\n",
      "\n",
      "=== Epoch 30/100 ===\n",
      "[Epoch 30/100] train_loss=0.2627, train_F1=0.5920 | val_loss=0.1744, val_F1=0.6149 | train_time=58.3s\n",
      "\n",
      "=== Epoch 31/100 ===\n",
      "[Epoch 31/100] train_loss=0.2750, train_F1=0.5867 | val_loss=0.1732, val_F1=0.6114 | train_time=41.9s\n",
      "\n",
      "=== Epoch 32/100 ===\n",
      "[Epoch 32/100] train_loss=0.2689, train_F1=0.5941 | val_loss=0.1804, val_F1=0.5781 | train_time=42.3s\n",
      "\n",
      "=== Epoch 33/100 ===\n",
      "[Epoch 33/100] train_loss=0.2582, train_F1=0.5980 | val_loss=0.1700, val_F1=0.6162 | train_time=42.2s\n",
      "\n",
      "=== Epoch 34/100 ===\n",
      "[Epoch 34/100] train_loss=0.2525, train_F1=0.6032 | val_loss=0.1683, val_F1=0.6091 | train_time=51.4s\n",
      "\n",
      "=== Epoch 35/100 ===\n",
      "[Epoch 35/100] train_loss=0.2593, train_F1=0.6036 | val_loss=0.1719, val_F1=0.6321 | train_time=48.7s\n",
      "*** New best frame-F1=0.6321, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 36/100 ===\n",
      "[Epoch 36/100] train_loss=0.2552, train_F1=0.6022 | val_loss=0.1747, val_F1=0.5855 | train_time=56.4s\n",
      "\n",
      "=== Epoch 37/100 ===\n",
      "[Epoch 37/100] train_loss=0.2548, train_F1=0.6013 | val_loss=0.1813, val_F1=0.5601 | train_time=44.9s\n",
      "\n",
      "=== Epoch 38/100 ===\n",
      "[Epoch 38/100] train_loss=0.2559, train_F1=0.6044 | val_loss=0.1687, val_F1=0.6187 | train_time=51.6s\n",
      "\n",
      "=== Epoch 39/100 ===\n",
      "[Epoch 39/100] train_loss=0.2609, train_F1=0.6099 | val_loss=0.1721, val_F1=0.5990 | train_time=50.7s\n",
      "\n",
      "=== Epoch 40/100 ===\n",
      "[Epoch 40/100] train_loss=0.2371, train_F1=0.6153 | val_loss=0.1646, val_F1=0.6417 | train_time=46.2s\n",
      "*** New best frame-F1=0.6417, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 41/100 ===\n",
      "[Epoch 41/100] train_loss=0.2439, train_F1=0.6116 | val_loss=0.1775, val_F1=0.5743 | train_time=45.3s\n",
      "\n",
      "=== Epoch 42/100 ===\n",
      "[Epoch 42/100] train_loss=0.2357, train_F1=0.6193 | val_loss=0.1787, val_F1=0.5748 | train_time=43.3s\n",
      "\n",
      "=== Epoch 43/100 ===\n",
      "[Epoch 43/100] train_loss=0.2440, train_F1=0.6149 | val_loss=0.1650, val_F1=0.6050 | train_time=46.2s\n",
      "\n",
      "=== Epoch 44/100 ===\n",
      "[Epoch 44/100] train_loss=0.2432, train_F1=0.6149 | val_loss=0.1625, val_F1=0.6221 | train_time=42.0s\n",
      "\n",
      "=== Epoch 45/100 ===\n",
      "[Epoch 45/100] train_loss=0.2413, train_F1=0.6147 | val_loss=0.1576, val_F1=0.6267 | train_time=53.7s\n",
      "\n",
      "=== Epoch 46/100 ===\n",
      "[Epoch 46/100] train_loss=0.2313, train_F1=0.6211 | val_loss=0.1589, val_F1=0.6375 | train_time=41.7s\n",
      "\n",
      "=== Epoch 47/100 ===\n",
      "[Epoch 47/100] train_loss=0.2394, train_F1=0.6185 | val_loss=0.1579, val_F1=0.6528 | train_time=45.3s\n",
      "*** New best frame-F1=0.6528, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 48/100 ===\n",
      "[Epoch 48/100] train_loss=0.2369, train_F1=0.6212 | val_loss=0.1596, val_F1=0.6082 | train_time=50.2s\n",
      "\n",
      "=== Epoch 49/100 ===\n",
      "[Epoch 49/100] train_loss=0.2426, train_F1=0.6206 | val_loss=0.1616, val_F1=0.6086 | train_time=43.0s\n",
      "\n",
      "=== Epoch 50/100 ===\n",
      "[Epoch 50/100] train_loss=0.2421, train_F1=0.6177 | val_loss=0.1581, val_F1=0.6250 | train_time=50.7s\n",
      "\n",
      "=== Epoch 51/100 ===\n",
      "[Epoch 51/100] train_loss=0.2343, train_F1=0.6288 | val_loss=0.1622, val_F1=0.5988 | train_time=51.6s\n",
      "\n",
      "=== Epoch 52/100 ===\n",
      "[Epoch 52/100] train_loss=0.2320, train_F1=0.6267 | val_loss=0.1511, val_F1=0.6536 | train_time=47.8s\n",
      "*** New best frame-F1=0.6536, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 53/100 ===\n",
      "[Epoch 53/100] train_loss=0.2425, train_F1=0.6264 | val_loss=0.1597, val_F1=0.6084 | train_time=42.0s\n",
      "\n",
      "=== Epoch 54/100 ===\n",
      "[Epoch 54/100] train_loss=0.2235, train_F1=0.6318 | val_loss=0.1527, val_F1=0.6375 | train_time=48.4s\n",
      "\n",
      "=== Epoch 55/100 ===\n",
      "[Epoch 55/100] train_loss=0.2321, train_F1=0.6317 | val_loss=0.1506, val_F1=0.6483 | train_time=50.2s\n",
      "\n",
      "=== Epoch 56/100 ===\n",
      "[Epoch 56/100] train_loss=0.2272, train_F1=0.6314 | val_loss=0.1492, val_F1=0.6456 | train_time=50.9s\n",
      "\n",
      "=== Epoch 57/100 ===\n",
      "[Epoch 57/100] train_loss=0.2351, train_F1=0.6336 | val_loss=0.1504, val_F1=0.6359 | train_time=49.8s\n",
      "\n",
      "=== Epoch 58/100 ===\n",
      "[Epoch 58/100] train_loss=0.2277, train_F1=0.6347 | val_loss=0.1525, val_F1=0.6371 | train_time=55.0s\n",
      "\n",
      "=== Epoch 59/100 ===\n",
      "[Epoch 59/100] train_loss=0.2283, train_F1=0.6309 | val_loss=0.1487, val_F1=0.6446 | train_time=45.3s\n",
      "\n",
      "=== Epoch 60/100 ===\n",
      "[Epoch 60/100] train_loss=0.2294, train_F1=0.6366 | val_loss=0.1480, val_F1=0.6619 | train_time=48.3s\n",
      "*** New best frame-F1=0.6619, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 61/100 ===\n",
      "[Epoch 61/100] train_loss=0.2214, train_F1=0.6357 | val_loss=0.1470, val_F1=0.6435 | train_time=46.3s\n",
      "\n",
      "=== Epoch 62/100 ===\n",
      "[Epoch 62/100] train_loss=0.2167, train_F1=0.6338 | val_loss=0.1556, val_F1=0.6076 | train_time=48.8s\n",
      "\n",
      "=== Epoch 63/100 ===\n",
      "[Epoch 63/100] train_loss=0.2275, train_F1=0.6308 | val_loss=0.1496, val_F1=0.6413 | train_time=49.0s\n",
      "\n",
      "=== Epoch 64/100 ===\n",
      "[Epoch 64/100] train_loss=0.2213, train_F1=0.6424 | val_loss=0.1475, val_F1=0.6651 | train_time=45.8s\n",
      "*** New best frame-F1=0.6651, saved to E:\\DL_audiotomidi\\checkpoints\\compactgru_cqt_best_cqt.pt ***\n",
      "\n",
      "=== Epoch 65/100 ===\n",
      "[Epoch 65/100] train_loss=0.2257, train_F1=0.6440 | val_loss=0.1607, val_F1=0.5966 | train_time=45.3s\n",
      "\n",
      "=== Epoch 66/100 ===\n",
      "[Epoch 66/100] train_loss=0.2150, train_F1=0.6469 | val_loss=0.1440, val_F1=0.6510 | train_time=45.2s\n",
      "\n",
      "=== Epoch 67/100 ===\n",
      "[Epoch 67/100] train_loss=0.2167, train_F1=0.6482 | val_loss=0.1490, val_F1=0.6264 | train_time=42.3s\n",
      "\n",
      "=== Epoch 68/100 ===\n",
      "[Epoch 68/100] train_loss=0.2161, train_F1=0.6449 | val_loss=0.1470, val_F1=0.6373 | train_time=50.3s\n",
      "\n",
      "=== Epoch 69/100 ===\n",
      "[Epoch 69/100] train_loss=0.2302, train_F1=0.6468 | val_loss=0.1484, val_F1=0.6267 | train_time=42.0s\n",
      "\n",
      "=== Epoch 70/100 ===\n",
      "[Epoch 70/100] train_loss=0.2195, train_F1=0.6451 | val_loss=0.1441, val_F1=0.6395 | train_time=42.4s\n",
      "\n",
      "=== Epoch 71/100 ===\n",
      "[Epoch 71/100] train_loss=0.2111, train_F1=0.6449 | val_loss=0.1437, val_F1=0.6510 | train_time=42.3s\n",
      "\n",
      "=== Epoch 72/100 ===\n",
      "[Epoch 72/100] train_loss=0.2165, train_F1=0.6458 | val_loss=0.1470, val_F1=0.6282 | train_time=47.9s\n",
      "\n",
      "=== Epoch 73/100 ===\n",
      "[Epoch 73/100] train_loss=0.2213, train_F1=0.6479 | val_loss=0.1423, val_F1=0.6571 | train_time=49.9s\n",
      "\n",
      "=== Epoch 74/100 ===\n",
      "[Epoch 74/100] train_loss=0.2113, train_F1=0.6557 | val_loss=0.1420, val_F1=0.6447 | train_time=51.5s\n",
      "\n",
      "=== Epoch 75/100 ===\n",
      "[Epoch 75/100] train_loss=0.2102, train_F1=0.6566 | val_loss=0.1408, val_F1=0.6600 | train_time=42.1s\n",
      "\n",
      "=== Epoch 76/100 ===\n",
      "[Epoch 76/100] train_loss=0.2111, train_F1=0.6536 | val_loss=0.1436, val_F1=0.6389 | train_time=44.7s\n",
      "\n",
      "=== Epoch 77/100 ===\n",
      "[Epoch 77/100] train_loss=0.2174, train_F1=0.6506 | val_loss=0.1435, val_F1=0.6462 | train_time=45.0s\n",
      "\n",
      "=== Epoch 78/100 ===\n",
      "[Epoch 78/100] train_loss=0.2128, train_F1=0.6510 | val_loss=0.1420, val_F1=0.6598 | train_time=55.5s\n",
      "\n",
      "=== Epoch 79/100 ===\n",
      "[Epoch 79/100] train_loss=0.2111, train_F1=0.6528 | val_loss=0.1435, val_F1=0.6397 | train_time=48.7s\n",
      "\n",
      "=== Epoch 80/100 ===\n",
      "[Epoch 80/100] train_loss=0.2030, train_F1=0.6584 | val_loss=0.1458, val_F1=0.6271 | train_time=55.5s\n",
      "\n",
      "=== Epoch 81/100 ===\n",
      "[Epoch 81/100] train_loss=0.2172, train_F1=0.6481 | val_loss=0.1416, val_F1=0.6483 | train_time=59.6s\n",
      "\n",
      "=== Epoch 82/100 ===\n",
      "[Epoch 82/100] train_loss=0.2098, train_F1=0.6592 | val_loss=0.1426, val_F1=0.6443 | train_time=51.8s\n",
      "\n",
      "=== Epoch 83/100 ===\n",
      "[Epoch 83/100] train_loss=0.2175, train_F1=0.6587 | val_loss=0.1404, val_F1=0.6516 | train_time=50.8s\n",
      "\n",
      "=== Epoch 84/100 ===\n",
      "[Epoch 84/100] train_loss=0.2093, train_F1=0.6543 | val_loss=0.1405, val_F1=0.6479 | train_time=43.4s\n",
      "\n",
      "=== Epoch 85/100 ===\n",
      "[Epoch 85/100] train_loss=0.2129, train_F1=0.6541 | val_loss=0.1415, val_F1=0.6432 | train_time=47.9s\n",
      "\n",
      "=== Epoch 86/100 ===\n",
      "[Epoch 86/100] train_loss=0.2034, train_F1=0.6596 | val_loss=0.1412, val_F1=0.6439 | train_time=42.9s\n",
      "\n",
      "=== Epoch 87/100 ===\n",
      "[Epoch 87/100] train_loss=0.2159, train_F1=0.6545 | val_loss=0.1400, val_F1=0.6516 | train_time=49.0s\n",
      "\n",
      "=== Epoch 88/100 ===\n",
      "[Epoch 88/100] train_loss=0.2084, train_F1=0.6582 | val_loss=0.1401, val_F1=0.6496 | train_time=45.3s\n",
      "\n",
      "=== Epoch 89/100 ===\n",
      "[Epoch 89/100] train_loss=0.2098, train_F1=0.6546 | val_loss=0.1403, val_F1=0.6487 | train_time=41.3s\n",
      "\n",
      "=== Epoch 90/100 ===\n",
      "[Epoch 90/100] train_loss=0.2051, train_F1=0.6590 | val_loss=0.1392, val_F1=0.6553 | train_time=48.0s\n",
      "\n",
      "=== Epoch 91/100 ===\n",
      "[Epoch 91/100] train_loss=0.2062, train_F1=0.6560 | val_loss=0.1390, val_F1=0.6579 | train_time=49.7s\n",
      "\n",
      "=== Epoch 92/100 ===\n",
      "[Epoch 92/100] train_loss=0.2066, train_F1=0.6610 | val_loss=0.1417, val_F1=0.6393 | train_time=47.8s\n",
      "\n",
      "=== Epoch 93/100 ===\n",
      "[Epoch 93/100] train_loss=0.2149, train_F1=0.6520 | val_loss=0.1398, val_F1=0.6497 | train_time=51.1s\n",
      "\n",
      "=== Epoch 94/100 ===\n",
      "[Epoch 94/100] train_loss=0.2136, train_F1=0.6571 | val_loss=0.1405, val_F1=0.6466 | train_time=52.4s\n",
      "\n",
      "=== Epoch 95/100 ===\n",
      "[Epoch 95/100] train_loss=0.2106, train_F1=0.6541 | val_loss=0.1396, val_F1=0.6521 | train_time=48.4s\n",
      "\n",
      "=== Epoch 96/100 ===\n",
      "[Epoch 96/100] train_loss=0.2032, train_F1=0.6611 | val_loss=0.1393, val_F1=0.6540 | train_time=48.0s\n",
      "\n",
      "=== Epoch 97/100 ===\n",
      "[Epoch 97/100] train_loss=0.2071, train_F1=0.6555 | val_loss=0.1393, val_F1=0.6543 | train_time=45.7s\n",
      "\n",
      "=== Epoch 98/100 ===\n",
      "[Epoch 98/100] train_loss=0.2064, train_F1=0.6577 | val_loss=0.1393, val_F1=0.6538 | train_time=49.9s\n",
      "\n",
      "=== Epoch 99/100 ===\n",
      "[Epoch 99/100] train_loss=0.2144, train_F1=0.6543 | val_loss=0.1393, val_F1=0.6544 | train_time=45.3s\n",
      "\n",
      "=== Epoch 100/100 ===\n",
      "[Epoch 100/100] train_loss=0.2054, train_F1=0.6600 | val_loss=0.1393, val_F1=0.6545 | train_time=45.2s\n",
      "\n",
      "=== TOTAL TRAINING TIME: 1.57 hours ===\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>lr</td><td>▂▃▄██████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>time/total_hours</td><td>▁</td></tr><tr><td>time/train_epoch_sec</td><td>▃▅▁▃█▄▃▇▄▂▄▂▄▄▃▃▂▅▂▄▄▄▄▃▃▂▂▄▃▆▆▅▂▃▂▄▃▄▃▃</td></tr><tr><td>train/frame_F1</td><td>▁▂▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>train/loss</td><td>█▆▅▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/frame_F1</td><td>▁▂▂▁▃▅▆▆▆▅▄▆▆▅▇▆▅▆▇▇▆▆▆▇▇▆█▇███▇████████</td></tr><tr><td>val/loss</td><td>█▆▅▅▄▃▂▂▂▂▂▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>lr</td><td>0</td></tr><tr><td>time/total_hours</td><td>1.57479</td></tr><tr><td>time/train_epoch_sec</td><td>45.21986</td></tr><tr><td>train/frame_F1</td><td>0.65999</td></tr><tr><td>train/loss</td><td>0.20542</td></tr><tr><td>val/frame_F1</td><td>0.6545</td></tr><tr><td>val/loss</td><td>0.13929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CompactBiGRU_cqt</strong> at: <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/wvrj8oyq' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi/runs/wvrj8oyq</a><br> View project at: <a href='https://wandb.ai/armaga-hse-university/DL_audiotomidi' target=\"_blank\">https://wandb.ai/armaga-hse-university/DL_audiotomidi</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251117_003624-wvrj8oyq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation frame-F1: 0.6651157952048441\n"
     ]
    }
   ],
   "source": [
    "with wandb.init(\n",
    "    project=\"DL_audiotomidi\",\n",
    "    name=\"CompactBiGRU_cqt\",\n",
    "    config=wandb_config\n",
    ") as run:\n",
    "\n",
    "    best_val_frame_f1 = train(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=DEVICE,\n",
    "        n_epochs=NUM_EPOCHS,\n",
    "        run=run,\n",
    "        checkpoint_path=best_ckpt_path,\n",
    "        threshold=THRESHOLD,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        sr=SR,\n",
    "        log_interval=50\n",
    "    )\n",
    "\n",
    "print(\"Best validation frame-F1:\", best_val_frame_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f925e2-c9aa-4a46-ab17-14d5da084583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompactBiGRU(\n",
       "  (input_proj): Linear(in_features=252, out_features=96, bias=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): ResidualBiGRUBlock(\n",
       "      (gru): GRU(96, 160, batch_first=True, bidirectional=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (proj): Linear(in_features=96, out_features=320, bias=True)\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): ResidualBiGRUBlock(\n",
       "      (gru): GRU(320, 160, batch_first=True, bidirectional=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=320, out_features=88, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(best_ckpt_path, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3043a139-32a7-4923-a1fc-2fdadcf3f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataset_helpers import PianoRollDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TEST_CHUNK_LEN = 512  # for CNN we don't need to chop the spectrogram into chunks, \n",
    "                      # but for RNN and CRNN we have to\n",
    "TEST_BATCH_SIZE = 8\n",
    "\n",
    "test_ds = PianoRollDataset(\n",
    "    root_dir=str(PREPROCESSED_ROOT),\n",
    "    split=\"test\",\n",
    "    spec_type=SPEC_TYPE,\n",
    "    chunk_len=TEST_CHUNK_LEN,\n",
    "    random_crop=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46fb886c-6c6d-4280-8eed-aa4d69e89a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test frame-level metrics ===\n",
      "accuracy: 97.52%\n",
      "precision: 65.92%\n",
      "recall: 74.15%\n",
      "frame_f1: 69.79%\n"
     ]
    }
   ],
   "source": [
    "from scripts.evaluate import compute_frame_micro_metrics\n",
    "\n",
    "frame_metrics = compute_frame_micro_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    DEVICE,\n",
    "    threshold=0.6\n",
    ")\n",
    "\n",
    "print(\"=== Test frame-level metrics ===\")\n",
    "for k, v in frame_metrics.items():\n",
    "    if k in (\"tp\", \"fp\", \"fn\"):\n",
    "        continue\n",
    "    print(f\"{k}: {v * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0616621-d41d-4f32-a271-0e8b7a3dfaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test note-level metrics ===\n",
      "accuracy: 32.60%\n",
      "precision: 39.51%\n",
      "recall: 65.11%\n",
      "note_f1: 49.17%\n"
     ]
    }
   ],
   "source": [
    "from scripts.evaluate import compute_note_micro_metrics\n",
    "\n",
    "note_metrics = compute_note_micro_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    DEVICE,\n",
    "    threshold=0.7,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    sr=SR,\n",
    "    onset_tolerance=0.05\n",
    ")\n",
    "\n",
    "print(\"=== Test note-level metrics ===\")\n",
    "for k, v in note_metrics.items():\n",
    "    if k in (\"tp\", \"fp\", \"fn\"):\n",
    "        continue\n",
    "    print(f\"{k}: {v * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fa253-6cc0-4989-943d-4ae14e2f649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.inference.py import get_piano_roll, predict, plot_comparison, measure_efficiency\n",
    "\n",
    "# Test track with corresponding MIDI\n",
    "AUDIO_PATH = \"test_long.wav\"\n",
    "MIDI_PATH = \"test_long.midi\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio, _ = librosa.load(AUDIO_PATH, sr=SR, mono=True)\n",
    "\n",
    "pred_probs, spec = predict(model, audio, DEVICE)\n",
    "\n",
    "gt_roll = get_piano_roll(MIDI_PATH, SR, HOP_LENGTH)\n",
    "\n",
    "plot_comparison(spec, pred_probs, gt_roll, SR, HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a89c62-3acf-466a-b032-ebdfa7812b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = measure_efficiency(model, device='cpu', duration_sec=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMT (PyTorch CUDA)",
   "language": "python",
   "name": "amt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
